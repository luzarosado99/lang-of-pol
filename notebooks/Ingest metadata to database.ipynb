{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Ayah Ahmad\n",
    "# Date: ~9/1/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, glob, pickle, os, psycopg2 , pprint\n",
    "from pathlib import Path\n",
    "import functools\n",
    "\n",
    "def invocation_counter(func):\n",
    "    inv_counter = 0\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def decorating_function(*args, **kwargs):\n",
    "        nonlocal inv_counter\n",
    "        inv_counter += 1\n",
    "        func(*args, **kwargs)\n",
    "\n",
    "    def info():\n",
    "        return inv_counter\n",
    "\n",
    "    def clear():\n",
    "        inv_counter = 0\n",
    "\n",
    "    decorating_function.clear = clear\n",
    "    decorating_function.info = info\n",
    "    return decorating_function\n",
    "### customization of tables ###\n",
    "TABLE_NAME = \"individual_audiofile_metadata\"\n",
    "TABLE_COLUMNS = \"file_name varchar(200), file_location varchar(200), file_length_seconds numeric, day int, month int, time int, year int, zone varchar(10)\"\n",
    "sql_table_creation = f\"CREATE TABLE {TABLE_NAME} ({TABLE_COLUMNS});\"\n",
    "\n",
    "TABLE2_NAME = \"vad_metadata\"\n",
    "TABLE2_COLUMNS = \"file_name varchar(200), file_location varchar(200), nonsilent_minutes num, nonsilent_slices int[]\" # TODO add db, pydub to this statement\n",
    "sql_table2_creation = f\"CREATE TABLE {TABLE2_NAME} ({TABLE2_COLUMNS});\"\n",
    "\n",
    "TABLE3_NAME = \"daily_audio_metadata\"\n",
    "TABLE3_COLUMNS = \"directory_name varchar(200), directory_location varchar(200), complete_data boolean, day_length_minutes numeric, files_total_silence int[], has_silent_files boolean\"\n",
    "sql_table3_creation = f\"CREATE TABLE {TABLE3_NAME} ({TABLE3_COLUMNS});\"\n",
    "\n",
    "### filepaths/locations ###\n",
    "sql_path = f\"zone.sql\"\n",
    "core_path='/media/4tb/data/'\n",
    "\n",
    "### connection to psycopg2 ###\n",
    "try:\n",
    "    conn = psycopg2.connect(host=\"lop-db.uchicago.edu\", sslrootcert=lop-db.uchicago.edu.ca, sslcert=lop-db.uchicago.edu-cert.pem, sslkey=lop-db.uchicago.edu-key.pem, port=5432, user=\"t-9ayah\", database=\"lop\", dbname=\"lop\")\n",
    "except:\n",
    "    conn = psycopg2.connect(\"host=lop-db.uchicago.edu sslmode=require sslrootcert=lop-db.uchicago.edu.ca sslcert=lop-db.uchicago.edu-cert.pem sslkey=lop-db.uchicago.edu-key.pem port=5432 user=t-9ayah dbname=lop\")\n",
    "curr = conn.cursor()\n",
    "conn.rollback()\n",
    "### creation of tables ###\n",
    "#try:\n",
    "#    curr.execute(\"\"\"\n",
    "#        CREATE TABLE individual_audiofile_metadata(\n",
    "#        file_name varchar(30) PRIMARY KEY,\n",
    "#        file_location varchar(70),\n",
    "#        file_length_seconds integer,\n",
    "#        date timestamp,\n",
    "#        zone integer)\n",
    "#    \"\"\")\n",
    "#    conn.commit()\n",
    "#except psycopg2.errors.DuplicateTable:\n",
    "#    pass\n",
    "#except psycopg2.errors.InFailedSqlTransaction as e:\n",
    "#    print(\"ERROR: \", e)\n",
    "#    conn.rollback()\n",
    "##try:\n",
    "##    curr.execute(\"\"\"\n",
    "##        CREATE TABLE vad_metadata(\n",
    "##        file_name varchar(30) PRIMARY KEY,\n",
    "##        file_location varchar(70),\n",
    "##        nonsilent_minutes integer,\n",
    "##        nonsilent_slices int[]\n",
    "##        )\n",
    "##    \"\"\")\n",
    "##    conn.commit()\n",
    "##except psycopg2.errors.DuplicateTable:\n",
    "##    pass\n",
    "##except psycopg2.errors.InFailedSqlTransaction as e:\n",
    "##    print(\"ERROR: \", e)\n",
    "##    conn.rollback()\n",
    "#try:\n",
    "#    curr.execute(\"\"\"\n",
    "#        CREATE TABLE daily_audio_metadata(\n",
    "#        date timestamp,\n",
    "#        directory_location varchar(70) PRIMARY KEY,\n",
    "#        complete_data boolean,\n",
    "#        day_length_minutes integer,\n",
    "#        files_total_silence varchar[],\n",
    "#        has_silent_files boolean)\n",
    "#    \"\"\")\n",
    "#    conn.commit()\n",
    "#except psycopg2.errors.DuplicateTable:\n",
    "#    pass\n",
    "#except psycopg2.errors.InFailedSqlTransaction as e:\n",
    "#    print(\"ERROR: \", e)\n",
    "#    conn.rollback()\n",
    "\n",
    "### general functions ###\n",
    "def sql_insertion_input(*args):\n",
    "    \"\"\"creates a line of the insert table command\"\"\"\n",
    "    ENTRY = ', '.join([str(i) for i in args])\n",
    "    return f\"{ENTRY}\"\n",
    "\n",
    "def from_pickle_metafile(pickle_path, sql_path, metadata_endswith):\n",
    "    \"\"\" converts a pickle file to an sql table \"\"\"\n",
    "    pkl_fil = open(pickle_path, 'rb')\n",
    "    dictionary = pickle.load(pkl_fil)\n",
    "    pkl_fil.close()\n",
    "    for key in dictionary.keys():\n",
    "        if key.endswith(\".mp3\") or key.endswith(\".wav\"):\n",
    "            file_location = os.path.join(os.path.split(pickle_path)[0], key)\n",
    "            prop_dict = dictionary[key]\n",
    "            if metadata_endswith == \"vad_dict.pkl\":\n",
    "                 try:\n",
    "                    generated_sql_statement = vad_insertion_from_properties(key, file_location, zone, prop_dict)\n",
    "                 except Exception as e:\n",
    "                    print(e)\n",
    "                    conn.rollback()\n",
    "                    generated_sql_statement = vad_insertion_from_properties(key, file_location, zone, prop_dict)\n",
    "            elif metadata_endswith == \"metadata_dict.pkl\":\n",
    "                try:\n",
    "                    generated_sql_statement = insertion_from_properties(key, file_location, zone, prop_dict)\n",
    "                except psycopg2.errors.UniqueViolation:\n",
    "                    pass\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "def zone_folder_iter(base_path, metadata_endswith, isdir=False):\n",
    "    \"\"\" finds all the metadata pickle files in each date directory \"\"\"\n",
    "    available_files = os.listdir(base_path)\n",
    "    available_folders = [i for i in available_files if i.startswith(\"Zone\")]\n",
    "    path_to_folder = [os.path.join(base_path, zone) for zone in available_folders]\n",
    "    for f in range(len(path_to_folder)):\n",
    "        global zone\n",
    "        zone = available_folders[f]\n",
    "        date_folder_iter(path_to_folder[f], metadata_endswith, isdir)\n",
    "        \n",
    "def date_folder_iter(path_to_folder, metadata_endswith, isdir=False):\n",
    "    \"\"\" finds all the metadata pickle files in each date directory \"\"\"\n",
    "    for subdir,directory,files in os.walk(path_to_folder):\n",
    "        for fil in files:\n",
    "            print(\"directory\", directory)\n",
    "            print(files)\n",
    "            if fil.endswith(metadata_endswith) and isdir==False:\n",
    "                pickle_path = os.path.join(path_to_folder,subdir,fil)\n",
    "                try:\n",
    "                    from_pickle_metafile(pickle_path, sql_path, metadata_endswith)\n",
    "                except Exception as e:\n",
    "                   print(e)\n",
    "                   print(fil)\n",
    "                   print(path_to_folder)\n",
    "                   conn.rollback()\n",
    "                   from_pickle_metafile(pickle_path, sql_path, metadata_endswith)\n",
    "                   pass\n",
    "            elif fil.endswith(metadata_endswith) and isdir==True:\n",
    "                pickle_path = os.path.join(path_to_folder,subdir,fil)\n",
    "                try:\n",
    "                    daily_from_pickle_metafile(pickle_path, sql_path, metadata_endswith)\n",
    "                except psycopg2.errors.InFailedSqlTransaction as e:\n",
    "                    conn.rollback()\n",
    "                    daily_from_pickle_metafile(pickle_path, sql_path, metadata_endswith)\n",
    "### individual_audiofile_metadata-specific functions ###\n",
    "@invocation_counter\n",
    "def insertion_from_properties(file_name, file_location, zone, prop_dict):\n",
    "    \"\"\" uses mp3 properties to generate the insert line \"\"\"\n",
    "    recording_start_dict = prop_dict['recording_start']\n",
    "    day = recording_start_dict['day']\n",
    "    file_length_seconds = prop_dict.get('file_length_seconds', 0)\n",
    "    time = recording_start_dict['time']\n",
    "    year = recording_start_dict['year']\n",
    "    month = recording_start_dict['month']\n",
    "    if len(str(time)) == 4:\n",
    "        date = f\"{year}-{month}-{day} {int((str(time))[:2])}:{int((str(time)[2:]))}\"\n",
    "    elif len(str(time))==3:\n",
    "        date = f\"{year}-{month}-{day} 0{int((str(time))[:1])}:{int((str(time)[1:]))}\"\n",
    "    elif len(str(time)) == 2:\n",
    "        date = f\"{year}-{month}-{day} 00:{int((str(time)[:2]))}\"\n",
    "    curr.execute(f\"INSERT INTO {TABLE_NAME}(file_name, file_location, file_length_seconds, date, zone) VALUES{file_name, file_location, file_length_seconds, date, int(zone[4:])}\")\n",
    "    conn.commit()\n",
    "    print(\"committed a ..\")\n",
    "@invocation_counter\n",
    "def vad_insertion_from_properties(file_name, file_location, zone, vad_prop_dict):\n",
    "    \"\"\" uses mp3 properties to generate the insert line \"\"\"\n",
    "    if len(vad_prop_dict) == 0 or file_name.startswith(\"Zone\"):\n",
    "        return\n",
    "    vad_program = vad_prop_dict.get('pydub', \"other\")\n",
    "    db = vad_program.get(-24, \"none\")\n",
    "    nonsilent_minutes = db['nonsilent_minutes']\n",
    "    nonsilent_slices = db[\"nonsilent_slices\"]\n",
    "    s = str(nonsilent_slices).replace(\"[\",\"{\")\n",
    "    l = s.replace(\"]\",\"}\")\n",
    "    slices = str(l)\n",
    "    curr.execute(f\"INSERT INTO {TABLE2_NAME}(file_name, file_location, nonsilent_minutes, nonsilent_slices) VALUES{file_name, file_location, nonsilent_minutes, slices}\")\n",
    "    conn.commit()\n",
    "### daily_audio_metadata-specific functions ###\n",
    "@invocation_counter\n",
    "def daily_insertion_from_properties(directory_location, zone, dictionary, metadata_endswith):\n",
    "    if len(dictionary) == 0:\n",
    "        return\n",
    "    try:\n",
    "        day_length_minutes = dictionary[\"day_length_minutes\"]\n",
    "    except Exception as e:\n",
    "        print(directory_location)\n",
    "        print(zone)\n",
    "        pprint.pprint(dictionary)\n",
    "        return\n",
    "    try:\n",
    "        files_total_silence = str(dictionary[\"files_total_silence\"])\n",
    "    except Exception as e:\n",
    "        pprint.pprint(dictionary)\n",
    "        pass\n",
    "    complete_data = dictionary[\"complete_data\"]\n",
    "    has_silent_files = dictionary[\"has_silent_files\"]\n",
    "    directory_name = os.path.split(directory_location)[1]\n",
    "    daily_entries = sql_insertion_input(str(directory_name), directory_location, day_length_minutes, files_total_silence, complete_data, has_silent_files)\n",
    "    f = str(files_total_silence).replace(\"[\",\"{\")\n",
    "    i = f.replace(\"]\",\"}\")\n",
    "    l = i.replace(\"'\",'\"')\n",
    "    files = str(l)\n",
    "    date = directory_location.replace(\"_\", \"-\")\n",
    "    curr.execute(f\"INSERT INTO {TABLE3_NAME} VALUES{str(directory_name), directory_location, complete_data, day_length_minutes, files, has_silent_files}\")\n",
    "    conn.commit()\n",
    "    print(\"committed a daily\")\n",
    "\n",
    "def daily_from_pickle_metafile(pickle_path, sql_path, metadata_endswith):\n",
    "    pkl_fil = open(pickle_path, 'rb')\n",
    "    dictionary = pickle.load(pkl_fil)\n",
    "    pkl_fil.close()\n",
    "    directory_location = os.path.split(pickle_path)[0]\n",
    "    try:\n",
    "        daily_generated_sql_statement = daily_insertion_from_properties(directory_location, zone, dictionary, metadata_endswith)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        conn.rollback()\n",
    "        daily_generated_sql_statement = daily_insertion_from_properties(directory_location, zone, dictionary, metadata_endswith)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    #zone_folder_iter(core_path, \"metadata_dict.pkl\")\n",
    "    #print(insertion_from_properties.info())\n",
    "    zone_folder_iter(core_path, \"vad_dict.pkl\")\n",
    "    print(vad_insertion_from_properties.info())\n",
    "    #zone_folder_iter(core_path, \"metadata_dict.pkl\", True)\n",
    "    #print(daily_insertion_from_properties.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
